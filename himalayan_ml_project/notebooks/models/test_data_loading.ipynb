{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a256854b",
   "metadata": {},
   "source": [
    "# Test Data Loading\n",
    "\n",
    "**Author**: Divyanshu Patel - 23BAI1214\n",
    "\n",
    "This notebook tests if the data loading is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab5b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data loading from notebook...\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append(os.path.join('..', '..', 'src'))\n",
    "\n",
    "# Import custom modules\n",
    "from data_loader import load_data, create_master_dataset\n",
    "\n",
    "print(\"Testing data loading from notebook...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160ebc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Current working directory: d:\\VIT_class\\5_semester\\ML\\Project\\myProject\\himalayan_ml_minimal\\notebooks\\models\n",
      "Script location: d:\\VIT_class\\5_semester\\ML\\Project\\myProject\\himalayan_ml_minimal\\src\n",
      "Found data directory: d:\\VIT_class\\5_semester\\ML\\Project\\myProject\\himalayan_ml_minimal\\data\n",
      "Loading expedition data...\n",
      "Loaded expeditions: (11425, 65)\n",
      "Loading member data...\n",
      "Loaded members: (89000, 61)\n",
      "Loading peak data...\n",
      "Loaded peaks: (480, 23)\n",
      "Data loaded successfully!\n",
      "Expeditions shape: (11425, 65)\n",
      "Members shape: (89000, 61)\n",
      "Peaks shape: (480, 23)\n",
      "Creating master dataset...\n",
      "Expeditions-Members join: (89089, 124)\n",
      "Final master dataset: (89089, 146)\n",
      "Created master dataset: (89089, 146)\n",
      "First few rows of master dataset:\n",
      "       expid peakid  year  season   host            route1 route2 route3  \\\n",
      "0  ANN260101   ANN2  1960  Spring  Nepal  NW Ridge-W Ridge    NaN    NaN   \n",
      "1  ANN260101   ANN2  1960  Spring  Nepal  NW Ridge-W Ridge    NaN    NaN   \n",
      "2  ANN260101   ANN2  1960  Spring  Nepal  NW Ridge-W Ridge    NaN    NaN   \n",
      "3  ANN260101   ANN2  1960  Spring  Nepal  NW Ridge-W Ridge    NaN    NaN   \n",
      "4  ANN260101   ANN2  1960  Spring  Nepal  NW Ridge-W Ridge    NaN    NaN   \n",
      "\n",
      "  route4 nation  ...       phost  pstatus   pyear  pseason  pmonth  pday  \\\n",
      "0    NaN     UK  ...  Nepal only  Climbed  1960.0   Spring     May  17.0   \n",
      "1    NaN     UK  ...  Nepal only  Climbed  1960.0   Spring     May  17.0   \n",
      "2    NaN     UK  ...  Nepal only  Climbed  1960.0   Spring     May  17.0   \n",
      "3    NaN     UK  ...  Nepal only  Climbed  1960.0   Spring     May  17.0   \n",
      "4    NaN     UK  ...  Nepal only  Climbed  1960.0   Spring     May  17.0   \n",
      "\n",
      "      pexpid   pcountry                                        psummiters  \\\n",
      "0  ANN260101  UK, Nepal  Richard Grant, Chris Bonington, Ang Nyima Sherpa   \n",
      "1  ANN260101  UK, Nepal  Richard Grant, Chris Bonington, Ang Nyima Sherpa   \n",
      "2  ANN260101  UK, Nepal  Richard Grant, Chris Bonington, Ang Nyima Sherpa   \n",
      "3  ANN260101  UK, Nepal  Richard Grant, Chris Bonington, Ang Nyima Sherpa   \n",
      "4  ANN260101  UK, Nepal  Richard Grant, Chris Bonington, Ang Nyima Sherpa   \n",
      "\n",
      "  psmtnote  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 146 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "print(\"Loading and preprocessing data...\")\n",
    "\n",
    "# Load the real Himalayan expedition dataset\n",
    "expeditions, members, peaks = load_data()\n",
    "\n",
    "if expeditions is not None:\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(f\"Expeditions shape: {expeditions.shape}\")\n",
    "    print(f\"Members shape: {members.shape}\")\n",
    "    print(f\"Peaks shape: {peaks.shape}\")\n",
    "    \n",
    "    # Create master dataset\n",
    "    df = create_master_dataset(expeditions, members, peaks)\n",
    "    if df is not None:\n",
    "        print(f\"Created master dataset: {df.shape}\")\n",
    "        print(\"First few rows of master dataset:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"Failed to create master dataset\")\n",
    "else:\n",
    "    print(\"Could not load real data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c66cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Data files not found. Please download the Himalayan expedition dataset from Kaggle:\n",
      "https://www.kaggle.com/datasets/majunbajun/himalayan-climbing-expeditions\n",
      "And place the following files in the data/ directory:\n",
      "- expeditions.csv\n",
      "- members.csv\n",
      "- peaks.csv\n",
      "Could not load real data. Creating sample data for demonstration.\n",
      "Created sample dataset: (1000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "print(\"Loading and preprocessing data...\")\n",
    "\n",
    "# Load the real Himalayan expedition dataset\n",
    "# Make sure you've downloaded the dataset from Kaggle and placed it in data/\n",
    "expeditions, members, peaks = load_data()\n",
    "\n",
    "if expeditions is not None:\n",
    "    print(\"Data loaded successfully!\")\n",
    "    \n",
    "    # Create master dataset by joining all three DataFrames\n",
    "    df = create_master_dataset(expeditions, members, peaks)\n",
    "    print(f\"Created master dataset: {df.shape}\")\n",
    "else:\n",
    "    print(\"Could not load real data. Creating sample data for demonstration.\")\n",
    "    \n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    sample_data = {\n",
    "        'age': np.random.randint(20, 65, n_samples),\n",
    "        'sex': np.random.choice(['M', 'F'], n_samples),\n",
    "        'season': np.random.choice(['Spring', 'Autumn', 'Winter', 'Summer'], n_samples),\n",
    "        'members': np.random.randint(1, 20, n_samples),\n",
    "        'hired_staff': np.random.randint(0, 15, n_samples),\n",
    "        'heightm': np.random.randint(6000, 8900, n_samples),\n",
    "        'o2used': np.random.choice([True, False], n_samples),\n",
    "        'totmembers': np.random.randint(1, 20, n_samples),\n",
    "        'success1': np.random.choice([True, False], n_samples)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(f\"Created sample dataset: {df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
